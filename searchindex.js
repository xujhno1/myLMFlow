Search.setIndex({"docnames": ["about/authors", "about/changelog", "about/index", "api/_autosummary/lmflow.args", "autoapi/index", "autoapi/lmflow/args/index", "autoapi/lmflow/datasets/dataset/index", "autoapi/lmflow/datasets/index", "autoapi/lmflow/index", "autoapi/lmflow/models/auto_model/index", "autoapi/lmflow/models/base_model/index", "autoapi/lmflow/models/decoder_model/index", "autoapi/lmflow/models/encoder_decoder_model/index", "autoapi/lmflow/models/hf_decoder_model/index", "autoapi/lmflow/models/hf_encoder_decoder_model/index", "autoapi/lmflow/models/index", "autoapi/lmflow/models/interfaces/index", "autoapi/lmflow/models/interfaces/tunable/index", "autoapi/lmflow/models/regression_model/index", "autoapi/lmflow/models/text_regression_model/index", "autoapi/lmflow/pipeline/auto_pipeline/index", "autoapi/lmflow/pipeline/base_aligner/index", "autoapi/lmflow/pipeline/base_pipeline/index", "autoapi/lmflow/pipeline/base_tuner/index", "autoapi/lmflow/pipeline/evaluator/index", "autoapi/lmflow/pipeline/finetuner/index", "autoapi/lmflow/pipeline/index", "autoapi/lmflow/pipeline/inferencer/index", "autoapi/lmflow/pipeline/raft_aligner/index", "autoapi/lmflow/pipeline/utils/index", "autoapi/lmflow/pipeline/utils/raft_trainer/index", "autoapi/lmflow/utils/constants/index", "autoapi/lmflow/utils/data_utils/index", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index", "autoapi/lmflow/utils/flash_attention/index", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index", "autoapi/lmflow/utils/index", "autoapi/lmflow/version/index", "documentation/data", "documentation/index", "documentation/infer", "documentation/model", "documentation/tuning", "examples/DATASETS", "examples/TASK_GUIDE", "examples/checkpoints", "examples/index", "examples/medical_finetune", "examples/raft", "examples/reward_modeling", "index"], "filenames": ["about/authors.md", "about/changelog.md", "about/index.md", "api/_autosummary/lmflow.args.rst", "autoapi/index.rst", "autoapi/lmflow/args/index.rst", "autoapi/lmflow/datasets/dataset/index.rst", "autoapi/lmflow/datasets/index.rst", "autoapi/lmflow/index.rst", "autoapi/lmflow/models/auto_model/index.rst", "autoapi/lmflow/models/base_model/index.rst", "autoapi/lmflow/models/decoder_model/index.rst", "autoapi/lmflow/models/encoder_decoder_model/index.rst", "autoapi/lmflow/models/hf_decoder_model/index.rst", "autoapi/lmflow/models/hf_encoder_decoder_model/index.rst", "autoapi/lmflow/models/index.rst", "autoapi/lmflow/models/interfaces/index.rst", "autoapi/lmflow/models/interfaces/tunable/index.rst", "autoapi/lmflow/models/regression_model/index.rst", "autoapi/lmflow/models/text_regression_model/index.rst", "autoapi/lmflow/pipeline/auto_pipeline/index.rst", "autoapi/lmflow/pipeline/base_aligner/index.rst", "autoapi/lmflow/pipeline/base_pipeline/index.rst", "autoapi/lmflow/pipeline/base_tuner/index.rst", "autoapi/lmflow/pipeline/evaluator/index.rst", "autoapi/lmflow/pipeline/finetuner/index.rst", "autoapi/lmflow/pipeline/index.rst", "autoapi/lmflow/pipeline/inferencer/index.rst", "autoapi/lmflow/pipeline/raft_aligner/index.rst", "autoapi/lmflow/pipeline/utils/index.rst", "autoapi/lmflow/pipeline/utils/raft_trainer/index.rst", "autoapi/lmflow/utils/constants/index.rst", "autoapi/lmflow/utils/data_utils/index.rst", "autoapi/lmflow/utils/flash_attention/gpt_neo_flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/index.rst", "autoapi/lmflow/utils/flash_attention/llama_flash_attention/index.rst", "autoapi/lmflow/utils/index.rst", "autoapi/lmflow/version/index.rst", "documentation/data.md", "documentation/index.md", "documentation/infer.md", "documentation/model.md", "documentation/tuning.md", "examples/DATASETS.md", "examples/TASK_GUIDE.md", "examples/checkpoints.md", "examples/index.md", "examples/medical_finetune.md", "examples/raft.md", "examples/reward_modeling.md", "index.md"], "titles": ["Contributors", "Changelog", "About", "lmflow.args", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.args</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.auto_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.hf_encoder_decoder_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.interfaces.tunable</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.models.text_regression_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.auto_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.base_tuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.evaluator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.finetuner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.inferencer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.raft_aligner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.pipeline.utils.raft_trainer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.data_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.gpt_neo_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils.flash_attention.llama_flash_attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">lmflow.version</span></code>", "Data", "Documentation", "Inference", "Model", "Fine-tuning", "Dataset", "LMFlow Benchmark Guide", "Checkpoints", "Examples", "Finetune", "Reward rAnked FineTuning (RAFT)", "Reward Modeling", "LMFlow"], "terms": {"shizh": [0, 50], "diao": [0, 50], "rui": [0, 50], "pan": [0, 50], "hanz": [0, 50], "dong": [0, 50], "ka": 0, "shun": 0, "shum": [0, 50], "jipeng": [0, 50], "zhang": [0, 50], "wei": [0, 50], "xiong": [0, 50], "tong": [0, 50], "The": [1, 5, 6, 7, 11, 12, 13, 14, 20, 24, 25, 27, 28, 30, 32, 43, 48, 49, 50], "first": [1, 30, 44, 45, 49], "public": 1, "task": [1, 13, 14, 30, 46], "tune": [1, 13, 14, 23, 25, 30, 47, 48, 49], "instruct": [1, 49], "user": [1, 43, 44, 48, 50], "defin": [1, 3, 5, 6, 7, 30, 43, 48], "dataset": [1, 3, 4, 5, 8, 13, 14, 19, 21, 23, 24, 25, 27, 28, 30, 32, 46, 47, 48, 49, 50], "A": [1, 6, 7, 11, 12, 13, 14, 19, 21, 23, 24, 28, 30, 32, 49], "simpl": [1, 30, 49], "extens": [1, 48, 50], "api": [1, 50], "develop": 1, "effici": [1, 50], "finetun": [1, 4, 8, 26, 43, 45, 50], "lora": [1, 13, 14, 48, 49, 50], "simplifi": [1, 24, 25, 27, 28, 49, 50], "model": [1, 3, 4, 5, 8, 21, 23, 24, 25, 27, 28, 30, 43, 45, 46, 47, 48, 50], "infer": [1, 13, 14, 19, 24, 27, 43, 50], "framework": [1, 48, 49], "changelog": [2, 50], "version": [2, 3, 4, 5, 8], "0": [2, 8, 13, 24, 27, 28, 30, 37, 45, 49, 50], "1": [2, 4, 5, 6, 7, 8, 13, 24, 30, 37, 43, 46, 47, 50], "mar": 2, "28": [2, 50], "2023": [2, 50], "contributor": [2, 50], "thi": [3, 4, 5, 6, 7, 11, 12, 13, 14, 28, 30, 32, 43, 44, 48, 49, 50], "script": [3, 5, 30, 45, 47, 48, 49], "dataclass": [3, 5], "modelargu": [3, 5, 24, 25, 27, 28, 47], "datasetargu": [3, 5, 6, 7, 24, 25, 27, 28, 47], "contain": [3, 4, 5, 6, 7, 11, 12, 24, 25, 27, 28, 30, 43], "argument": [3, 5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 32, 47], "us": [3, 5, 10, 11, 12, 13, 14, 17, 18, 22, 24, 30, 31, 32, 43, 44, 45, 46, 48, 49, 50], "train": [3, 5, 13, 14, 25, 28, 30, 32, 43, 44, 48, 49, 50], "It": [3, 5, 13, 14, 24, 30, 49, 50], "import": [3, 5, 24, 30, 47, 48, 50], "sever": [3, 5, 13, 14, 30, 32, 43, 44, 46], "modul": 3, "includ": [3, 5, 6, 7, 30, 32, 49, 50], "field": [3, 5, 49, 50], "from": [3, 5, 6, 7, 13, 14, 24, 30, 32, 45, 47, 48, 49, 50], "type": [3, 5, 6, 7, 9, 19, 30, 43, 44, 48, 49], "option": [3, 5, 6, 7, 11, 12, 13, 14, 19, 25, 28, 30, 35, 45], "require_vers": [3, 5], "transform": [3, 5, 13, 14, 30, 47], "util": [3, 4, 5, 8, 26, 28, 50], "model_for_causal_lm_map": [3, 5], "trainingargu": [3, 5, 30], "model_config_class": [3, 5], "i": [3, 5, 13, 14, 21, 23, 24, 28, 30, 43, 45, 48, 49, 50], "assign": [3, 5], "list": [3, 5, 13, 14, 30, 32, 43, 50], "config": [3, 5, 47, 49], "class": 3, "model_typ": [3, 5], "tupl": [3, 5, 30, 35], "extract": [3, 5, 32], "page": [4, 50], "auto": [4, 5], "gener": [4, 5, 13, 14, 18, 24, 28, 30, 32, 45, 46, 48, 49, 50], "document": [4, 30], "lmflow": [4, 46, 47, 48, 49], "interfac": [4, 8, 13, 14, 15], "tunabl": [4, 8, 13, 14, 15, 16, 23], "auto_model": [4, 8, 15], "base_model": [4, 8, 11, 12, 15, 18], "decoder_model": [4, 8, 13, 15], "encoder_decoder_model": [4, 8, 14, 15], "hf_decoder_model": [4, 8, 15], "hf_encoder_decoder_model": [4, 8, 15], "regression_model": [4, 8, 15, 19], "text_regression_model": [4, 8, 15], "pipelin": [4, 8, 43, 47, 48, 50], "raft_train": [4, 8, 26, 29], "auto_pipelin": [4, 8, 26, 47], "base_align": [4, 8, 26, 28], "base_pipelin": [4, 8, 21, 23, 24, 26, 27], "base_tun": [4, 8, 25, 26], "evalu": [4, 5, 8, 26, 30, 43, 45, 49, 50], "inferenc": [4, 5, 8, 26, 43], "raft_align": [4, 8, 26, 48], "flash_attent": [4, 8, 36], "gpt_neo_flash_attent": [4, 8, 34, 36], "llama_flash_attent": [4, 8, 34, 36], "constant": [4, 8, 36], "data_util": [4, 8, 36], "arg": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 28, 30, 32, 47], "creat": [4, 6, 7, 10, 11, 12, 17, 18, 22, 24, 30, 46, 49, 50], "sphinx": 4, "autoapi": 4, "sourc": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 37, 43, 50], "decor": 5, "paramet": [5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 32, 49, 50], "can": [5, 13, 14, 30, 43, 44, 45, 48, 49, 50], "configur": 5, "model_name_or_path": [5, 44, 45, 49], "str": [5, 6, 7, 13, 14, 27, 30, 32, 48], "string": [5, 6, 7, 13, 14, 27, 30, 32], "repres": [5, 6, 7, 13, 14, 24], "path": [5, 13, 14, 19, 30, 44, 45, 47], "name": [5, 13, 14, 19, 20, 30, 32, 44], "pretrain": [5, 13, 14, 30, 45, 50], "checkpoint": [5, 30, 46, 48], "weight": [5, 24, 50], "initi": [5, 6, 7, 13, 14, 19, 24, 25, 27, 28, 30, 47], "If": [5, 30, 32, 44, 47, 49, 50], "none": [5, 6, 7, 13, 14, 24, 28, 30, 32, 33, 35, 49], "scratch": 5, "provid": [5, 10, 11, 12, 13, 14, 17, 18, 22, 24, 30, 43, 44, 46, 48, 49, 50], "config_overrid": 5, "default": [5, 6, 7, 13, 14, 30, 32], "set": [5, 13, 14, 30, 32, 43, 45, 46, 48, 49], "overrid": [5, 30], "when": [5, 30, 49], "config_nam": 5, "differ": [5, 6, 7, 13, 14, 30, 45], "tokenizer_nam": 5, "token": [5, 13, 14, 24, 28, 30, 47, 49], "cache_dir": 5, "directori": [5, 13, 14, 24, 30, 43], "where": [5, 24, 43, 48, 49], "download": [5, 43, 44, 45, 48], "huggingfac": [5, 6, 7, 13, 14, 45, 49], "co": 5, "store": 5, "use_fast_token": 5, "bool": [5, 30, 32, 35], "boolean": 5, "indic": [5, 43], "whether": [5, 13, 14, 30], "fast": 5, "back": [5, 49], "librari": [5, 30], "model_revis": 5, "specif": [5, 49, 50], "branch": [5, 44], "tag": [5, 30], "commit": [5, 30], "id": [5, 13, 14], "use_auth_token": 5, "run": [5, 24, 25, 28, 30, 43, 44, 45, 49], "cli": 5, "login": 5, "necessari": [5, 30], "privat": 5, "torch_dtyp": 5, "dtype": [5, 30], "load": [5, 6, 7, 13, 14, 24, 25, 27, 28, 30, 32, 45], "under": [5, 30, 43, 44, 48, 50], "pass": [5, 30, 47, 50], "automat": [5, 9, 20, 30], "deriv": 5, "": [5, 30, 44, 47, 48, 49, 50], "use_ram_optimized_load": [5, 44], "disk": 5, "map": [5, 6, 7, 19, 47, 49], "memori": 5, "enough": 5, "lora_model_path": [5, 45], "arch_typ": 5, "use_lora": 5, "lora_r": 5, "int": [5, 13, 14, 27, 30, 32, 49], "lora_alpha": 5, "lora_target_modul": 5, "lora_dropout": 5, "float": [5, 19, 24, 27, 30, 48], "save_aggregated_lora": 5, "use_flash_attent": 5, "__post_init__": 5, "languag": [5, 13, 14, 24, 25, 30, 48, 50], "dataset_path": [5, 45, 49], "dataset_nam": [5, 44], "valu": [5, 30, 33, 44, 48], "custom": [5, 30, 43, 46, 49], "is_custom_dataset": 5, "data": [5, 6, 7, 19, 24, 25, 28, 30, 32, 43, 44, 45, 48, 49, 50], "fals": [5, 13, 14, 30, 33, 35, 44, 49], "customized_cache_dir": 5, "cach": [5, 30], "dataset_config_nam": 5, "via": [5, 48], "train_fil": 5, "input": [5, 13, 14, 19, 24, 27, 28, 30, 32, 35, 43, 44, 45, 49], "file": [5, 24, 30, 32, 43, 46, 47, 50], "text": [5, 13, 14, 24, 25, 32, 43, 45, 47, 48, 49], "validation_fil": 5, "perplex": 5, "max_train_sampl": 5, "an": [5, 10, 11, 12, 17, 18, 22, 30, 48, 49, 50], "integ": 5, "maximum": [5, 24, 25, 30], "number": [5, 24, 30, 48], "exampl": [5, 11, 12, 30, 32, 43, 44, 45, 48, 50], "debug": 5, "quicker": 5, "truncat": [5, 49], "max_eval_sampl": 5, "stream": [5, 48], "enabl": 5, "mode": [5, 30], "block_siz": 5, "sequenc": [5, 13, 14, 30], "length": [5, 13, 14, 24, 25, 30, 32], "after": [5, 43, 44], "block": [5, 25, 30], "size": [5, 24, 30], "also": [5, 11, 12, 24, 30, 44, 49, 50], "some": [5, 24, 30, 44, 49, 50], "addit": [5, 30], "further": [5, 50], "overwrite_cach": 5, "validation_split_percentag": [5, 49], "preprocessing_num_work": 5, "disable_group_text": 5, "demo_example_in_prompt": 5, "explanation_in_prompt": 5, "keep_linebreak": 5, "prompt_structur": [5, 27, 44, 45], "function": [5, 11, 12, 19, 28, 30, 48, 49, 50], "help": [5, 49, 50], "messag": [5, 6, 7, 30], "each": [5, 30, 43, 49], "hint": [5, 6, 7], "metadata": [5, 30], "inform": [5, 6, 7, 24, 30, 49, 50], "about": [5, 30, 48, 49, 50], "group_texts_batch_s": 5, "test_fil": 5, "finetunerargu": [5, 25], "base": [5, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 48, 49, 50], "adapt": [5, 13, 14, 30, 50], "eval_dataset_path": 5, "evaluatorargu": [5, 24], "local_rank": [5, 28], "For": [5, 30, 43, 46, 49, 50], "distribut": [5, 30], "random_shuffl": [5, 32], "use_wandb": [5, 24], "random_se": 5, "output_dir": [5, 30, 45], "mixed_precis": 5, "choic": [5, 32], "bf16": 5, "fp16": 5, "mix": 5, "precis": 5, "deepspe": [5, 13, 14, 30, 44, 45, 47], "json": [5, 6, 7, 30, 32, 43, 44, 45, 47, 49], "e": [5, 28, 30, 32, 44, 50], "g": [5, 30], "ds_config": [5, 13, 14, 44, 45], "alreadi": [5, 30, 49], "dict": [5, 6, 7, 30], "answer_typ": [5, 24, 32, 44, 45], "evaluate_block_s": 5, "metric": [5, 24, 30, 44], "inference_batch_size_per_devic": 5, "use_accelerator_for_evalu": 5, "inferencerargu": [5, 27], "devic": [5, 13, 14, 30], "do_sampl": 5, "raftalignerargu": [5, 28], "raft": [5, 46], "align": [5, 21, 28, 46], "output_reward_path": [5, 28], "output_min_length": [5, 28], "output_max_length": [5, 28], "num_raft_iter": 5, "raft_batch_s": 5, "top_reward_percentag": 5, "benchmarkingargu": 5, "lm_evaluation_metr": 5, "pipeline_argument_map": 5, "autoargu": [5, 47], "choos": [5, 30, 49], "get_pipeline_args_class": [5, 47], "python": [6, 7, 44, 45, 50], "code": [6, 7, 30], "method": [6, 7, 13, 14, 24, 30, 50], "manipul": [6, 7], "backend": [6, 7, 13, 14, 30], "hug": [6, 7, 43], "face": [6, 7], "dictionari": [6, 7, 24, 25, 30], "retriev": [6, 7], "dataset_typ": 6, "text_onli": [6, 19, 43, 44, 48, 49], "text2text": [6, 44, 46], "float_onli": [6, 48], "key_typ": 6, "key_inst": 6, "instanc": [6, 7, 13, 14, 19, 24, 25, 30, 43, 48, 49, 50], "data_arg": [6, 7, 20, 24, 25, 27, 28, 47], "kwarg": [6, 7, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23, 25, 28, 30], "object": [6, 7, 19, 24, 25, 27, 28, 30], "given": [6, 7, 19, 24, 25, 27, 28, 30, 44, 48, 49], "requir": [6, 7, 24, 25, 27, 28, 49, 50], "posit": [6, 7, 13, 14, 19, 25, 28, 48, 49, 50], "keyword": [6, 7, 13, 14, 19, 25, 28, 30], "_check_data_format": [6, 7], "check": [6, 7, 30], "structur": [6, 7, 49], "match": [6, 7], "rais": [6, 7, 30], "from_dict": [6, 7], "dict_obj": [6, 7], "return": [6, 7, 13, 14, 20, 24, 25, 27, 28, 30, 32, 48, 49], "format": [6, 7, 46], "key_1": [6, 7, 43], "value_1": [6, 7, 43], "key_2": [6, 7, 43], "2": [6, 7, 28, 43, 46, 47, 50], "value_2": [6, 7, 43], "self": [6, 7, 30, 33, 35], "classmethod": [6, 7, 9, 20], "create_from_dict": [6, 7, 48], "to_dict": [6, 7, 48], "get_backend": [6, 7], "get_backend_dataset": [6, 7], "backend_dataset": [6, 7], "get_data_arg": [6, 7], "get_typ": [6, 7], "internal_vers": 8, "__version__": [8, 37], "get": [9, 19, 28, 30, 44, 45, 47, 49], "correct": 9, "automodel": 9, "get_model": 9, "model_arg": [9, 13, 14, 19, 20, 24, 25, 27, 28, 47], "basemodel": [10, 11, 12, 18, 28], "abc": [10, 11, 12, 17, 18, 22], "helper": [10, 11, 12, 17, 18, 22, 30], "standard": [10, 11, 12, 17, 18, 22], "wai": [10, 11, 12, 17, 18, 22, 30, 43, 44, 45, 49], "inherit": [10, 11, 12, 17, 18, 22, 30], "one": [11, 12, 30, 44, 47, 48, 49], "line": [11, 12], "summari": [11, 12, 30], "program": [11, 12, 32], "termin": [11, 12], "period": [11, 12], "leav": [11, 12], "blank": [11, 12], "rest": [11, 12], "docstr": [11, 12], "should": [11, 12, 30, 49], "overal": [11, 12, 13, 14, 50], "descript": [11, 12, 30], "mai": [11, 12, 30, 44, 49], "brief": [11, 12], "export": [11, 12], "usag": [11, 12], "typic": [11, 12, 49], "foo": [11, 12], "classfoo": [11, 12], "bar": [11, 12], "functionbar": [11, 12], "decodermodel": [11, 13], "encoderdecodermodel": [12, 14], "call": [13, 14, 30], "hfdecodermodel": [13, 14, 24], "which": [13, 14, 21, 23, 24, 30, 43, 48, 49, 50], "wrapper": [13, 14, 30], "around": [13, 14], "ha": [13, 14, 24, 30, 43, 48], "__init__": [13, 14], "ar": [13, 14, 30, 43, 44, 45, 49, 50], "fine": [13, 14, 30, 39, 49, 50], "take": [13, 14, 24, 28, 30], "tune_strategi": [13, 14], "attent": [13, 14], "mask": [13, 14], "fed": [13, 14, 30], "support": [13, 14, 44, 45, 46, 48], "normal": [13, 14, 24], "allow": [13, 14, 30, 50], "howev": [13, 14, 45, 50], "strategi": [13, 14], "yet": [13, 14], "implement": [13, 14, 30, 44], "conveni": [13, 14, 50], "variou": [13, 14, 30, 43, 50], "nlp": [13, 14], "classif": [13, 14, 30], "question": [13, 14, 28, 43], "answer": [13, 14, 32, 43, 44, 49], "logger": [13, 14, 25, 28, 30], "models_support_flash_attent": 13, "llamaforcausallm": 13, "gptneoforcausallm": 13, "gpu": [13, 14, 30], "use_acceler": [13, 14], "revis": [13, 14, 19], "etc": [13, 14, 19, 30, 50], "configu": [13, 14], "add_special_token": 13, "true": [13, 24, 25, 30, 32, 49], "full": [13, 14, 49, 50], "tokenized_dataset": [13, 14, 25, 47], "without": [13, 30, 49], "ani": [13, 30, 49, 50], "lead": [13, 48], "trail": 13, "special": [13, 50], "thei": [13, 30, 43, 49], "begin": 13, "Of": 13, "sentenc": 13, "end": [13, 30, 48], "encod": [13, 14, 24, 43], "union": [13, 14, 30], "perform": [13, 14, 24, 25, 27, 28, 30, 48, 49, 50], "process": [13, 14, 24, 25, 27, 28, 30, 46, 47, 48, 49, 50], "output": [13, 14, 24, 28, 30, 32, 43], "hello": 13, "world": [13, 48], "101": 13, "7592": 13, "1010": 13, "2088": 13, "102": 13, "batch": [13, 24, 30, 32, 35, 49], "input_id": [13, 49], "attention_mask": [13, 33, 35, 49], "token_type_id": 13, "tensor": [13, 30, 35], "decod": [13, 14, 24, 32, 43], "singl": [13, 30, 43, 49], "prompt": [13, 14, 28, 43, 49, 50], "merge_lora_weight": [13, 14], "save": [13, 14, 30, 45, 50], "dir": [13, 14, 44], "save_full_model": [13, 14], "get_max_length": [13, 14, 47], "max": [13, 14, 24], "accept": [13, 14, 19, 24, 30, 43], "term": [13, 14], "get_token": [13, 14], "get_backend_model": [13, 14], "hfencoderdecodermodel": 14, "abstract": [14, 21, 23], "regress": [18, 19], "regressionmodel": [18, 19, 28], "textregressionmodel": 19, "register_inference_funct": [19, 48], "inference_func": 19, "regist": [19, 48], "result": [19, 48, 50], "onli": [19, 30, 43, 44, 47, 49, 50], "its": [20, 30, 50], "pipeline_map": 20, "autopipelin": [20, 47], "design": [20, 50], "get_pipelin": [20, 47], "pipeline_nam": [20, 47], "pipeline_arg": [20, 47], "basetun": [21, 23, 25], "subclass": [21, 23, 30], "basepipelin": [21, 22, 23, 24, 27], "basealign": [21, 28], "_check_if_align": 21, "reward_model": [21, 28, 48], "_check_if_tun": 23, "packag": [24, 46, 50], "constructor": 24, "three": [24, 43, 49], "relat": [24, 49, 50], "evaluator_arg": 24, "other": [24, 30, 49, 50], "two": [24, 30, 44, 49], "create_dataload": [24, 27], "test": [24, 30, 43, 45, 49, 50], "loader": 24, "iter": [24, 28, 30], "over": [24, 43, 49], "mini": 24, "Then": [24, 45, 49], "write": 24, "log": [24, 30, 44], "consol": 24, "bias": [24, 48], "_match": 24, "predicted_answ": 24, "groundtruth": 24, "accuraci": [24, 49, 50], "verbos": 24, "tunablemodel": [24, 25, 27, 47], "_evaluate_acc_with_acceler": 24, "_evaluate_acc_with_deepspe": 24, "_evaluate_ppl": 24, "_evaluate_nl": 24, "neg": [24, 44, 49, 50], "likelihood": [24, 44], "nll": [24, 46], "n": [24, 44, 50], "sum_": 24, "j": [24, 49], "w_i": 24, "ln": 24, "p": 24, "w_": 24, "context_window": 24, "sampl": [24, 30, 43, 48, 49], "th": 24, "here": [24, 30, 49], "start": [24, 30, 49], "p_": 24, "window_length": 24, "finetuner_arg": 25, "group_text": [25, 47], "model_max_length": [25, 47], "group": [25, 30, 47], "togeth": [25, 30], "form": [25, 30], "transform_dataset_in_plac": 25, "rstrip_partial_utf8": 27, "inferencer_arg": 27, "max_new_token": 27, "100": [27, 30, 49], "temperatur": 27, "output_dataset": 27, "stream_infer": 27, "context": [27, 30], "token_per_step": 27, "end_str": 27, "input_dataset": 27, "raftalign": 28, "aligner_arg": 28, "raft_aligner_arg": 28, "_initialize_train": 28, "training_arg": [28, 30], "trainer": [28, 30], "_load_dataset": 28, "selected_dataset": 28, "prepar": [28, 30, 44, 49, 50], "everi": [28, 30], "_load_input_dataset": 28, "dataload": [28, 30, 32], "torch": [28, 30, 32, 35], "_get_batch_dataset_top": 28, "batch_input": 28, "alpha": 28, "iter_id": 28, "16": 28, "48": 28, "infer_batch_s": 28, "8": [28, 50], "generation_kwarg": 28, "feed": [28, 30], "reward": [28, 46], "_is_native_cpu_amp_avail": 30, "default_callback": 30, "default_progress_callback": 30, "is_sagemaker_mp_post_1_10": 30, "skip_first_batch": 30, "training_args_nam": 30, "bin": 30, "trainer_state_nam": 30, "trainer_st": 30, "optimizer_nam": 30, "optim": 30, "pt": 30, "scheduler_nam": 30, "schedul": 30, "scaler_nam": 30, "scaler": 30, "rafttrain": 30, "modeling_util": 30, "pretrainedmodel": 30, "nn": [30, 49], "data_col": 30, "datacol": 30, "train_dataset": [30, 49], "eval_dataset": [30, 49], "tokenization_utils_bas": 30, "pretrainedtokenizerbas": 30, "model_init": 30, "callabl": 30, "compute_metr": 30, "trainer_util": 30, "evalpredict": 30, "callback": 30, "trainer_callback": 30, "trainercallback": 30, "lr_schedul": 30, "lambdalr": 30, "preprocess_logits_for_metr": 30, "featur": 30, "complet": [30, 50], "eval": [30, 49], "loop": 30, "pytorch": 30, "predict": 30, "must": [30, 47, 50], "tip": 30, "work": [30, 48, 49], "you": [30, 44, 45, 49, 50], "still": [30, 49, 50], "your": [30, 46, 48, 49], "own": [30, 43, 44, 48, 49], "long": [30, 43], "same": [30, 49], "tweak": 30, "Will": 30, "basic": 30, "tmp_trainer": 30, "current": [30, 43, 44], "element": [30, 50], "default_data_col": 30, "datacollatorwithpad": 30, "otherwis": 30, "iterabledataset": 30, "column": 30, "forward": [30, 33, 35], "remov": 30, "note": [30, 44, 50], "random": [30, 32], "fashion": 30, "either": 30, "intern": 30, "ident": 30, "all": [30, 45, 49, 50], "manual": 30, "seed": [30, 32], "epoch": 30, "have": [30, 43, 44, 45, 48, 49, 50], "set_epoch": 30, "rng": 30, "prepend": 30, "kei": [30, 33, 43, 44, 49], "preprocess": [30, 49], "pad": 30, "along": 30, "make": [30, 44, 49, 50], "easier": 30, "rerun": 30, "interrupt": 30, "reus": 30, "instanti": 30, "new": [30, 44, 49, 50], "zero": 30, "optuna": 30, "rai": 30, "sigopt": 30, "trial": [30, 49], "abl": [30, 49], "architectur": 30, "accord": 30, "hyper": 30, "layer": 30, "count": 30, "inner": 30, "dropout": 30, "probabl": [30, 49], "comput": 30, "add": [30, 44], "those": 30, "detail": [30, 44, 46, 49], "want": [30, 44, 49], "remove_callback": 30, "adamw": 30, "get_linear_schedule_with_warmup": 30, "control": 30, "logit": 30, "right": 30, "befor": [30, 50], "them": [30, 44, 45, 49, 50], "step": [30, 44, 46], "label": [30, 49], "onc": 30, "desir": [30, 49], "modif": 30, "made": [30, 49], "reflect": 30, "receiv": 30, "second": [30, 45], "doe": [30, 50], "alwai": [30, 49], "point": 30, "core": 30, "model_wrap": 30, "most": [30, 43, 49], "extern": 30, "case": [30, 45, 49], "more": [30, 48, 49, 50], "wrap": 30, "origin": [30, 45, 49], "again": 30, "distributeddataparallel": 30, "hasn": 30, "t": [30, 49], "been": 30, "is_model_parallel": 30, "switch": [30, 49], "parallel": 30, "mean": [30, 49], "split": [30, 49], "place_model_on_devic": 30, "place": [30, 49], "overridden": 30, "is_in_train": 30, "while": [30, 50], "add_callback": 30, "In": [30, 44, 45, 48, 49], "member": 30, "pop_callback": 30, "found": [30, 50], "error": 30, "pop": 30, "_move_model_to_devic": 30, "_set_signature_columns_if_need": 30, "_remove_unused_column": 30, "_get_collator_with_removed_column": 30, "collat": 30, "unus": 30, "_get_train_sampl": 30, "sampler": 30, "get_train_dataload": 30, "__len__": 30, "inject": 30, "behavior": 30, "_get_eval_sampl": 30, "get_eval_dataload": 30, "get_test_dataload": 30, "test_dataset": 30, "create_optimizer_and_schedul": 30, "num_training_step": 30, "setup": [30, 46], "learn": [30, 48, 49, 50], "rate": 30, "we": [30, 43, 44, 46, 47, 48, 49, 50], "reason": [30, 49], "well": [30, 48, 50], "someth": [30, 49], "els": [30, 47, 49], "init": 30, "through": 30, "create_optim": 30, "create_schedul": 30, "static": 30, "get_optimizer_cls_and_kwarg": 30, "session": 30, "up": [30, 49], "do": [30, 49, 50], "num_exampl": 30, "access": [30, 45, 50], "exist": 30, "estim": 30, "best": [30, 48, 49], "_hp_search_setup": 30, "hp": 30, "search": [30, 50], "_report_to_hp_search": 30, "_tune_save_checkpoint": 30, "call_model_init": 30, "torch_jit_model_ev": 30, "ipex_optimize_model": 30, "float32": 30, "_wrap_model": 30, "resume_from_checkpoint": 30, "ignore_keys_for_ev": 30, "is_first_tim": 30, "main": [30, 44, 47, 50], "entri": 30, "local": 30, "previou": [30, 48, 49], "equal": 30, "last": [30, 49], "present": 30, "resum": 30, "state": 30, "hyperparamet": 30, "ignor": 30, "gather": 30, "dure": 30, "hide": [30, 49], "deprec": 30, "_one_train": 30, "batch_siz": [30, 32], "_inner_training_loop": 30, "serv": [30, 50], "time": [30, 35, 49], "updat": [30, 49], "_get_output_dir": 30, "_load_from_checkpoint": 30, "_load_best_model": 30, "_issue_warnings_after_load": 30, "load_result": 30, "_maybe_log_save_evalu": 30, "tr_loss": 30, "_load_rng_stat": 30, "_save_checkpoint": 30, "_load_optimizer_and_schedul": 30, "hyperparameter_search": 30, "hp_space": 30, "compute_object": 30, "n_trial": 30, "20": 30, "direct": [30, 50], "minim": 30, "hpsearchbackend": 30, "hp_name": 30, "bestrun": 30, "launch": 30, "quantiti": 30, "determin": 30, "loss": [30, 49], "sum": 30, "warn": 30, "To": [30, 43, 48, 49, 50], "need": [30, 44, 45, 48, 49, 50], "reiniti": 30, "incompat": 30, "so": [30, 48, 49, 50], "space": [30, 49], "default_hp_space_optuna": 30, "default_hp_space_rai": 30, "default_hp_space_sigopt": 30, "depend": [30, 49], "maxim": [30, 50], "default_compute_object": 30, "greater": 30, "lower": 30, "pick": 30, "valid": 30, "training_util": 30, "instal": [30, 44], "create_studi": 30, "see": [30, 49], "http": [30, 44, 49, 50], "readthedoc": 30, "io": [30, 50], "en": 30, "stabl": 30, "refer": [30, 44, 46, 50], "studi": [30, 49], "html": 30, "doc": 30, "latest": 30, "api_doc": 30, "execut": [30, 44], "app": 30, "com": [30, 44, 50], "endpoint": 30, "experi": [30, 48], "run_summari": 30, "watch": 30, "_prepare_input": 30, "nest": 30, "convert": [30, 32, 45], "handl": 30, "potenti": 30, "compute_loss_context_manag": 30, "manag": 30, "autocast_smart_context_manag": 30, "cache_en": 30, "appropri": [30, 49], "autocast": 30, "situat": [30, 49], "training_step": 30, "target": [30, 50], "unpack": 30, "being": [30, 49], "expect": 30, "compute_loss": 30, "return_output": 30, "how": [30, 46, 49], "By": [30, 45, 50], "is_local_process_zero": 30, "machin": [30, 50], "is_world_process_zero": 30, "global": 30, "go": [30, 45], "save_model": 30, "_internal_cal": 30, "reload": 30, "from_pretrain": 30, "_save_tpu": 30, "_save": 30, "state_dict": 30, "store_flo": 30, "_sorted_checkpoint": 30, "checkpoint_prefix": 30, "prefix_checkpoint_dir": 30, "use_mtim": 30, "_rotate_checkpoint": 30, "ignore_kei": 30, "metric_key_prefix": 30, "respons": [30, 32, 48, 49, 50], "wish": 30, "lst": 30, "prefix": [30, 49], "bleu": 30, "eval_bleu": 30, "come": 30, "predictionoutput": 30, "like": [30, 44, 49, 50], "test_bleu": 30, "becaus": 30, "re": [30, 49], "dynam": 30, "concaten": 30, "arrai": 30, "index": [30, 50], "namedtupl": 30, "follow": [30, 43, 44, 49, 50], "np": 30, "ndarrai": 30, "label_id": 30, "evaluation_loop": 30, "prediction_loss_onli": 30, "evalloopoutput": 30, "share": [30, 48], "both": [30, 48, 50], "_nested_gath": 30, "numpi": [30, 32], "_pad_across_process": 30, "pad_index": 30, "recurs": 30, "safe": [30, 49], "prediction_step": 30, "floating_point_op": 30, "oper": 30, "backward": 30, "anoth": 30, "init_git_repo": 30, "at_init": 30, "git": [30, 44, 50], "repo": [30, 44], "hub_model_id": 30, "overwrite_output_dir": 30, "might": [30, 49], "wipe": 30, "out": [30, 49, 50], "create_model_card": 30, "licens": 30, "model_nam": [30, 44], "finetuned_from": 30, "dataset_tag": 30, "dataset_arg": 30, "draft": 30, "card": 30, "avail": [30, 43, 44, 50], "applic": [30, 50], "hub": 30, "One": 30, "identifi": 30, "_push_from_checkpoint": 30, "checkpoint_fold": 30, "push_to_hub": 30, "commit_messag": 30, "upload": 30, "push": 30, "finish": [30, 44], "url": [30, 50], "repositori": [30, 50], "track": 30, "progress": 30, "prediction_loop": 30, "_gather_and_numpifi": 30, "_add_sm_patterns_to_gitignor": 30, "sagemak": 30, "pattern": 30, "gitignor": 30, "commonli": [31, 50], "text_only_dataset_descript": 31, "text_only_dataset_detail": 31, "text2text_dataset_descript": 31, "text2text_dataset_detail": 31, "float_only_dataset_descript": 31, "text_only_dataset_long_descrit": 31, "text2text_dataset_long_descrit": 31, "dataset_description_map": 31, "instance_fields_map": 31, "set_random_se": 32, "cuda": 32, "load_data": 32, "file_nam": 32, "len": [32, 47, 49], "batchliz": 32, "shuffl": 32, "answer_extract": 32, "funtion": 32, "plain": 32, "b": [32, 44], "c": 32, "d": [32, 49], "mutipl": 32, "qa": 32, "_attn": 33, "queri": 33, "head_mask": 33, "hidden_st": [33, 35], "layer_past": 33, "use_cach": [33, 35], "output_attent": [33, 35], "replace_gpt_neo_attn_with_flash_attn": 33, "position_id": 35, "past_key_valu": 35, "shape": 35, "x": [35, 49], "channel": 35, "bsz": 35, "q_len": 35, "_prepare_decoder_attention_mask": 35, "input_shap": 35, "inputs_emb": 35, "past_key_values_length": 35, "replace_llama_attn_with_flash_attn": 35, "cd": [43, 44, 45, 48], "sh": [43, 44, 45, 48, 49], "strongli": 43, "encourag": [43, 48], "sinc": 43, "appli": [43, 50], "engin": 43, "techniqu": [43, 50], "As": [43, 49], "below": [43, 44, 50], "our": [43, 44, 45, 46, 47, 48, 50], "specifi": [43, 44], "path_to_dataset": 43, "data_1": 43, "data_2": 43, "another_data": 43, "shall": [43, 50], "four": 43, "key_3": 43, "3": [43, 44, 50], "key_4": 43, "4": [43, 50], "value_3": 43, "correspond": 43, "interpret": 43, "common": [43, 50], "raw": 43, "Its": [43, 50], "sample_text_1": 43, "sample_text_2": 43, "sample_text_3": 43, "example_dataset": 43, "train_50": 43, "abov": [43, 49], "mostli": 43, "pair": [43, 44], "sample_input_1": 43, "sample_output_1": 43, "sample_input_2": 43, "sample_output_2": 43, "sample_input_3": 43, "sample_output_3": 43, "test_13": 43, "easili": [44, 50], "fork": 44, "clone": [44, 50], "github": [44, 50], "usernam": 44, "checkout": 44, "conda": [44, 50], "9": [44, 50], "y": [44, 50], "activ": [44, 50], "mpi4pi": [44, 50], "pip": [44, 50], "decid": 44, "notic": 44, "chosen": [44, 49], "put": 44, "mkdir": 44, "mv": 44, "open": [44, 50], "py": [44, 45, 48, 49], "info": 44, "local_datset_group_map": 44, "local_datset_map": 44, "local_datset_answertype_map": 44, "combin": 44, "task_combin": 44, "task_1": 44, "task_2": 44, "rememb": 44, "separ": 44, "chang": 44, "item": 44, "human": [44, 48, 49, 50], "assist": [44, 49], "tee": 44, "log_dir": 44, "err": 44, "integr": 44, "eleutherai": [44, 49], "har": 44, "benchamrk": 44, "directli": [44, 45, 50], "command": [44, 49, 50], "simpli": 44, "lm_eval_dataset_map": 44, "pleas": [44, 50], "eleuth": 44, "tabl": 44, "exact": 44, "similarli": 44, "slightli": 45, "due": 45, "copyright": 45, "issu": [45, 48, 50], "facebookresearch": 45, "offici": 45, "hf": 45, "convert_llama_weights_to_hf": 45, "input_dir": 45, "model_s": 45, "7b": [45, 48, 49, 50], "good": [45, 49], "enjoi": [45, 49], "now": 45, "With": 45, "output_model": [45, 48], "obtain": [45, 48, 50], "similar": 45, "run_evaluation_with_lora": 45, "cuda_visible_devic": 45, "diff": 45, "alpaca": 45, "show": [46, 49], "problem": [46, 49], "textonli": 46, "llama": [46, 48, 49, 50], "sft": 46, "introduct": 46, "supervis": [46, 48], "rank": [46, 49], "algorithm": 46, "demo": 46, "benchmark": 46, "guid": [46, 49], "registr": 46, "lm": 46, "sy": 47, "hfargumentpars": 47, "tunable_model": 47, "def": [47, 48, 49], "pars": 47, "pipelineargu": 47, "parser": 47, "argv": 47, "endswith": 47, "let": [47, 49], "parse_json_fil": 47, "json_fil": 47, "o": 47, "abspath": 47, "parse_args_into_dataclass": 47, "todo": 47, "done": [47, 48], "main_process_first": 47, "desc": 47, "lm_dataset": 47, "tuned_model": 47, "unsupervis": 48, "foundat": [48, 50], "implicit": 48, "Such": 48, "low": 48, "qualiti": 48, "unfair": 48, "substanti": 48, "consequ": 48, "therefor": [48, 50], "ethic": 48, "prefer": [48, 49], "becom": 48, "crucial": [48, 50], "procedur": [48, 49], "ensur": 48, "behav": 48, "real": 48, "scenario": 48, "primarili": 48, "reli": [48, 50], "reinforc": [48, 49], "feedback": [48, 49], "rlhf": [48, 49], "overcom": 48, "rl": 48, "despit": [48, 50], "feasibl": 48, "ineffici": 48, "instabl": 48, "often": 48, "pose": 48, "signific": [48, 50], "challeng": [48, 49], "urgent": 48, "streamlin": [48, 50], "enhanc": [48, 50], "propos": 48, "suffici": 48, "reject": [48, 49], "ill": 48, "ones": 48, "construct": 48, "offlin": 48, "onlin": 48, "furthermor": 48, "gradient": 48, "free": 48, "black": 48, "box": 48, "demonstr": [48, 50], "larg": [48, 50], "movi": 48, "review": 48, "chatbot": 48, "topic": 48, "interact": [48, 49], "bot": 48, "favorit": 48, "wa": 48, "run_raft_align": 48, "llama7b": 48, "reward_of": 48, "part": 48, "reward_funct": 48, "text_dataset": 48, "data_dict": 48, "assert": 48, "text_list": 48, "reward_list": 48, "adjust": 49, "instructgpt": [49, 50], "paper": 49, "arxiv": 49, "org": 49, "ab": 49, "2203": 49, "02155": 49, "dahoa": 49, "hh": 49, "consist": 49, "particular": [49, 50], "compar": [49, 50], "112k": 49, "12": 49, "5k": 49, "what": 49, "kind": 49, "nois": 49, "did": 49, "dinosaur": 49, "didn": 49, "live": 49, "realli": 49, "hard": 49, "sai": 49, "find": 49, "would": 49, "ye": 49, "guess": 49, "lot": 49, "read": 49, "certain": 49, "amount": 49, "imagin": 49, "cant": 49, "stuff": 49, "don": 49, "know": 49, "10k": 49, "12k": 49, "10": 49, "hh_rlhf": 49, "ad": 49, "post": 49, "illustr": 49, "bui": 49, "protect": 49, "cell": 49, "phone": 49, "circumst": 49, "carri": 49, "pocket": 49, "purs": 49, "But": 49, "quick": 49, "actual": 49, "caus": 49, "harm": 49, "than": 49, "parent": 49, "home": 49, "could": 49, "damag": [49, 50], "screen": 49, "thing": 49, "troubl": 49, "turn": 49, "off": 49, "won": 49, "anyth": 49, "afford": 49, "replac": 49, "peopl": 49, "aren": 49, "thank": 49, "me": 49, "welcom": 49, "m": 49, "try": 49, "salam": 49, "witch": 49, "look": 49, "book": 49, "witchcraft": 49, "recommend": 49, "histor": 49, "salem": 49, "1692": 49, "interest": 49, "histori": 49, "persecut": 49, "coloni": 49, "america": 49, "cultur": 49, "phenomenon": 49, "excel": 49, "religion": 49, "declin": 49, "magic": 49, "popular": 49, "belief": 49, "sixteenth": 49, "seventeenth": 49, "centuri": 49, "england": 49, "keith": 49, "thoma": 49, "otherworld": 49, "anthropologi": 49, "superstit": 49, "jack": 49, "goodi": 49, "popish": 49, "plot": 49, "prelat": 49, "k": 49, "everett": 49, "edit": 49, "run_finetun": 49, "modifi": 49, "gpt": [49, 50], "neo": 49, "3b": 49, "project_dir": 49, "run_finetune_with_lora": 49, "involv": 49, "fortun": 49, "former": 49, "heater": 49, "give": 49, "fire": 49, "hazard": 49, "tell": 49, "fireplac": 49, "room": 49, "materi": 49, "feel": 49, "heat": 49, "touch": 49, "just": 49, "fuel": 49, "surround": 49, "sure": 49, "correctli": 49, "sort": 49, "That": 49, "glad": 49, "happi": 49, "teach": [49, 50], "my": 49, "kid": 49, "fort": 49, "build": 49, "Or": 49, "elabor": 49, "exactli": 49, "mayb": 49, "idea": 49, "There": 49, "mani": 49, "simplest": 49, "pile": 49, "furnitur": 49, "hous": 49, "although": 49, "bit": 49, "taller": 49, "sturdier": 49, "easi": 49, "fun": 49, "explor": 49, "improv": [49, 50], "run_reward_model": 49, "addition": 49, "select": 49, "percentag": 49, "load_dataset": 49, "build_dataset": 49, "assum": [49, 50], "organ": 49, "answer_posit": 49, "answer_neg": 49, "tokenized_po": 49, "tokenized_neg": 49, "chosen_input_id": 49, "chosen_attention_mask": 49, "rejected_input_id": 49, "rejected_attention_mask": 49, "data_fil": 49, "filter": 49, "lambda": 49, "512": 49, "idx_gap": 49, "rang": [49, 50], "logsigmoid": 49, "chosen_reward": 49, "rejected_reward": 49, "5": [49, 50], "record": 49, "remark": [49, 50], "79": 49, "52": 49, "wandb": 49, "ai": [49, 50], "weixiong5237": 49, "t3uwm8yp": 49, "71": 49, "64": [49, 50], "p2ju3r1a": 49, "rm": 49, "69": [49, 50], "24": [49, 50], "8fc1rcf8": 49, "65": [49, 50], "58": [49, 50], "7oemwynu": 49, "10000": 49, "toolbox": 50, "friendli": 50, "speedi": 50, "reliabl": 50, "entir": 50, "commun": 50, "backbon": 50, "galactica": 50, "light": 50, "extrem": 50, "few": 50, "33b": 50, "25mb": 50, "storag": 50, "orient": 50, "chatgpt": 50, "whole": 50, "achiev": 50, "expans": 50, "except": 50, "capac": 50, "attain": 50, "intellig": 50, "surpass": 50, "convent": 50, "grow": 50, "cater": 50, "maintain": 50, "compet": 50, "introduc": 50, "lightweight": 50, "toolkit": 50, "thoughtfulli": 50, "scalabl": 50, "tool": 50, "publicli": 50, "effect": 50, "thoroughli": 50, "goal": 50, "profici": 50, "medicin": 50, "mathemat": 50, "acquir": 50, "domain": 50, "better": 50, "subject": 50, "matter": 50, "medic": 50, "gain": 50, "knowledg": 50, "emphas": 50, "pubmedqa": 50, "medmcqa": 50, "observ": 50, "medqa": 50, "usml": 50, "averag": 50, "60": 50, "50": 50, "expert": 50, "78": 50, "87": 50, "90": 50, "85": 50, "175b": 50, "73": 50, "46": 50, "44": 50, "54": 50, "63": 50, "57": 50, "7": 50, "55": 50, "27": 50, "18": 50, "43": 50, "30": 50, "25": 50, "75": 50, "49": 50, "56": 50, "74": 50, "51": 50, "moreov": 50, "mmlu": 50, "verifi": 50, "robust": 50, "anatomi": 50, "clinic": 50, "colleg": 50, "biologi": 50, "genet": 50, "profession": 50, "39": 50, "40": 50, "32": 50, "36": 50, "30b": 50, "26": 50, "23": 50, "120b": 50, "59": 50, "68": 50, "6": 50, "opt": 50, "21": 50, "35": 50, "bloom": 50, "176b": 50, "37": 50, "29": 50, "gopher": 50, "280b": 50, "67": 50, "70": 50, "gpt3": 50, "72": 50, "61": 50, "66": 50, "natur": 50, "constraint": 50, "abil": 50, "multipl": 50, "unseen": 50, "understand": 50, "incorpor": 50, "cue": 50, "relev": 50, "hand": 50, "power": 50, "wide": 50, "area": 50, "approach": 50, "unlock": 50, "level": 50, "product": 50, "jsonl": 50, "optimalscal": 50, "readm": 50, "misc": 50, "author": 50, "kashun": 50, "titl": 50, "year": 50, "publish": 50, "journal": 50, "howpublish": 50, "aim": 50, "intend": 50, "li": 50, "sole": 50, "guarante": 50, "legal": 50, "compon": 50, "awar": 50, "risk": 50, "liabil": 50, "associ": 50, "commerci": 50, "technic": 50, "advic": 50, "held": 50, "indirect": 50, "incident": 50, "consequenti": 50, "improp": 50, "highlight": 50, "probabilist": 50, "seek": 50, "outcom": 50, "account": 50, "relianc": 50, "submit": 50}, "objects": {"": [[8, 0, 0, "-", "lmflow"]], "lmflow": [[8, 1, 1, "", "__version__"], [5, 0, 0, "-", "args"], [7, 0, 0, "-", "datasets"], [8, 1, 1, "", "internal_version"], [15, 0, 0, "-", "models"], [26, 0, 0, "-", "pipeline"], [36, 0, 0, "-", "utils"], [37, 0, 0, "-", "version"]], "lmflow.args": [[5, 2, 1, "", "AutoArguments"], [5, 2, 1, "", "BenchmarkingArguments"], [5, 2, 1, "", "DatasetArguments"], [5, 2, 1, "", "EvaluatorArguments"], [5, 2, 1, "", "FinetunerArguments"], [5, 2, 1, "", "InferencerArguments"], [5, 1, 1, "", "MODEL_CONFIG_CLASSES"], [5, 1, 1, "", "MODEL_TYPES"], [5, 2, 1, "", "ModelArguments"], [5, 1, 1, "", "PIPELINE_ARGUMENT_MAPPING"], [5, 2, 1, "", "RaftAlignerArguments"]], "lmflow.args.AutoArguments": [[5, 3, 1, "", "get_pipeline_args_class"]], "lmflow.args.BenchmarkingArguments": [[5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "lm_evaluation_metric"]], "lmflow.args.DatasetArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "", "block_size"], [5, 4, 1, "", "customized_cache_dir"], [5, 4, 1, "", "dataset_config_name"], [5, 4, 1, "", "dataset_name"], [5, 4, 1, "", "dataset_path"], [5, 4, 1, "", "disable_group_texts"], [5, 4, 1, "", "group_texts_batch_size"], [5, 4, 1, "", "is_custom_dataset"], [5, 4, 1, "", "keep_linebreaks"], [5, 4, 1, "", "max_eval_samples"], [5, 4, 1, "", "max_train_samples"], [5, 4, 1, "", "overwrite_cache"], [5, 4, 1, "", "preprocessing_num_workers"], [5, 4, 1, "", "streaming"], [5, 4, 1, "", "test_file"], [5, 4, 1, "", "train_file"], [5, 4, 1, "", "validation_file"], [5, 4, 1, "", "validation_split_percentage"]], "lmflow.args.EvaluatorArguments": [[5, 4, 1, "", "answer_type"], [5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "evaluate_block_size"], [5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "metric"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "output_dir"], [5, 4, 1, "", "prompt_structure"], [5, 4, 1, "", "random_seed"], [5, 4, 1, "", "random_shuffle"], [5, 4, 1, "", "use_accelerator_for_evaluator"], [5, 4, 1, "", "use_wandb"]], "lmflow.args.FinetunerArguments": [[5, 4, 1, "", "eval_dataset_path"]], "lmflow.args.InferencerArguments": [[5, 4, 1, "", "deepspeed"], [5, 4, 1, "", "device"], [5, 4, 1, "", "do_sample"], [5, 4, 1, "", "local_rank"], [5, 4, 1, "", "mixed_precision"], [5, 4, 1, "", "random_seed"]], "lmflow.args.ModelArguments": [[5, 3, 1, "", "__post_init__"], [5, 4, 1, "id0", "arch_type"], [5, 4, 1, "", "cache_dir"], [5, 4, 1, "", "config_name"], [5, 4, 1, "", "config_overrides"], [5, 4, 1, "", "lora_alpha"], [5, 4, 1, "", "lora_dropout"], [5, 4, 1, "", "lora_model_path"], [5, 4, 1, "", "lora_r"], [5, 4, 1, "", "lora_target_modules"], [5, 4, 1, "", "model_name_or_path"], [5, 4, 1, "", "model_revision"], [5, 4, 1, "", "model_type"], [5, 4, 1, "", "save_aggregated_lora"], [5, 4, 1, "", "tokenizer_name"], [5, 4, 1, "", "torch_dtype"], [5, 4, 1, "", "use_auth_token"], [5, 4, 1, "", "use_fast_tokenizer"], [5, 4, 1, "", "use_flash_attention"], [5, 4, 1, "", "use_lora"], [5, 4, 1, "", "use_ram_optimized_load"]], "lmflow.args.RaftAlignerArguments": [[5, 4, 1, "", "inference_batch_size_per_device"], [5, 4, 1, "", "num_raft_iteration"], [5, 4, 1, "", "output_max_length"], [5, 4, 1, "", "output_min_length"], [5, 4, 1, "", "output_reward_path"], [5, 4, 1, "", "raft_batch_size"], [5, 4, 1, "", "top_reward_percentage"]], "lmflow.datasets": [[7, 2, 1, "", "Dataset"], [6, 0, 0, "-", "dataset"]], "lmflow.datasets.Dataset": [[7, 3, 1, "", "_check_data_format"], [7, 3, 1, "", "create_from_dict"], [7, 3, 1, "", "from_dict"], [7, 3, 1, "", "get_backend"], [7, 3, 1, "", "get_backend_dataset"], [7, 3, 1, "", "get_data_args"], [7, 3, 1, "", "get_type"], [7, 3, 1, "", "map"], [7, 3, 1, "", "to_dict"]], "lmflow.datasets.dataset": [[6, 1, 1, "", "DATASET_TYPES"], [6, 2, 1, "", "Dataset"], [6, 1, 1, "", "KEY_INSTANCES"], [6, 1, 1, "", "KEY_TYPE"]], "lmflow.datasets.dataset.Dataset": [[6, 3, 1, "", "_check_data_format"], [6, 3, 1, "", "create_from_dict"], [6, 3, 1, "", "from_dict"], [6, 3, 1, "", "get_backend"], [6, 3, 1, "", "get_backend_dataset"], [6, 3, 1, "", "get_data_args"], [6, 3, 1, "", "get_type"], [6, 3, 1, "", "map"], [6, 3, 1, "", "to_dict"]], "lmflow.models": [[9, 0, 0, "-", "auto_model"], [10, 0, 0, "-", "base_model"], [11, 0, 0, "-", "decoder_model"], [12, 0, 0, "-", "encoder_decoder_model"], [13, 0, 0, "-", "hf_decoder_model"], [14, 0, 0, "-", "hf_encoder_decoder_model"], [16, 0, 0, "-", "interfaces"], [18, 0, 0, "-", "regression_model"], [19, 0, 0, "-", "text_regression_model"]], "lmflow.models.auto_model": [[9, 2, 1, "", "AutoModel"]], "lmflow.models.auto_model.AutoModel": [[9, 3, 1, "", "get_model"]], "lmflow.models.base_model": [[10, 2, 1, "", "BaseModel"]], "lmflow.models.decoder_model": [[11, 2, 1, "", "DecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, 2, 1, "", "EncoderDecoderModel"]], "lmflow.models.hf_decoder_model": [[13, 2, 1, "", "HFDecoderModel"], [13, 1, 1, "", "MODELS_SUPPORT_FLASH_ATTENTION"], [13, 1, 1, "", "logger"]], "lmflow.models.hf_decoder_model.HFDecoderModel": [[13, 3, 1, "", "decode"], [13, 3, 1, "", "encode"], [13, 3, 1, "", "get_backend_model"], [13, 3, 1, "", "get_max_length"], [13, 3, 1, "", "get_tokenizer"], [13, 3, 1, "", "inference"], [13, 3, 1, "", "merge_lora_weights"], [13, 3, 1, "", "save"], [13, 3, 1, "", "tokenize"]], "lmflow.models.hf_encoder_decoder_model": [[14, 2, 1, "", "HFEncoderDecoderModel"], [14, 1, 1, "", "logger"]], "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel": [[14, 3, 1, "", "decode"], [14, 3, 1, "", "encode"], [14, 3, 1, "", "get_backend_model"], [14, 3, 1, "", "get_max_length"], [14, 3, 1, "", "get_tokenizer"], [14, 3, 1, "", "inference"], [14, 3, 1, "", "merge_lora_weights"], [14, 3, 1, "", "save"], [14, 3, 1, "", "tokenize"]], "lmflow.models.interfaces": [[17, 0, 0, "-", "tunable"]], "lmflow.models.interfaces.tunable": [[17, 2, 1, "", "Tunable"]], "lmflow.models.regression_model": [[18, 2, 1, "", "RegressionModel"]], "lmflow.models.text_regression_model": [[19, 2, 1, "", "TextRegressionModel"]], "lmflow.models.text_regression_model.TextRegressionModel": [[19, 3, 1, "", "inference"], [19, 3, 1, "", "register_inference_function"]], "lmflow.pipeline": [[20, 0, 0, "-", "auto_pipeline"], [21, 0, 0, "-", "base_aligner"], [22, 0, 0, "-", "base_pipeline"], [23, 0, 0, "-", "base_tuner"], [24, 0, 0, "-", "evaluator"], [25, 0, 0, "-", "finetuner"], [27, 0, 0, "-", "inferencer"], [28, 0, 0, "-", "raft_aligner"], [29, 0, 0, "-", "utils"]], "lmflow.pipeline.auto_pipeline": [[20, 2, 1, "", "AutoPipeline"], [20, 1, 1, "", "PIPELINE_MAPPING"]], "lmflow.pipeline.auto_pipeline.AutoPipeline": [[20, 3, 1, "", "get_pipeline"]], "lmflow.pipeline.base_aligner": [[21, 2, 1, "", "BaseAligner"]], "lmflow.pipeline.base_aligner.BaseAligner": [[21, 3, 1, "", "_check_if_alignable"], [21, 3, 1, "", "align"]], "lmflow.pipeline.base_pipeline": [[22, 2, 1, "", "BasePipeline"]], "lmflow.pipeline.base_tuner": [[23, 2, 1, "", "BaseTuner"]], "lmflow.pipeline.base_tuner.BaseTuner": [[23, 3, 1, "", "_check_if_tunable"], [23, 3, 1, "", "tune"]], "lmflow.pipeline.evaluator": [[24, 2, 1, "", "Evaluator"]], "lmflow.pipeline.evaluator.Evaluator": [[24, 3, 1, "", "_evaluate_acc_with_accelerator"], [24, 3, 1, "", "_evaluate_acc_with_deepspeed"], [24, 3, 1, "", "_evaluate_nll"], [24, 3, 1, "", "_evaluate_ppl"], [24, 3, 1, "", "_match"], [24, 3, 1, "", "create_dataloader"], [24, 3, 1, "", "evaluate"]], "lmflow.pipeline.finetuner": [[25, 2, 1, "", "Finetuner"], [25, 1, 1, "", "logger"]], "lmflow.pipeline.finetuner.Finetuner": [[25, 3, 1, "", "group_text"], [25, 3, 1, "", "tune"]], "lmflow.pipeline.inferencer": [[27, 2, 1, "", "Inferencer"], [27, 5, 1, "", "rstrip_partial_utf8"]], "lmflow.pipeline.inferencer.Inferencer": [[27, 3, 1, "", "create_dataloader"], [27, 3, 1, "", "inference"], [27, 3, 1, "", "stream_inference"]], "lmflow.pipeline.raft_aligner": [[28, 2, 1, "", "RaftAligner"], [28, 1, 1, "", "logger"]], "lmflow.pipeline.raft_aligner.RaftAligner": [[28, 3, 1, "", "_get_batch_dataset_top"], [28, 3, 1, "", "_initialize_trainer"], [28, 3, 1, "", "_load_dataset"], [28, 3, 1, "", "_load_input_dataset"], [28, 3, 1, "", "align"]], "lmflow.pipeline.utils": [[30, 0, 0, "-", "raft_trainer"]], "lmflow.pipeline.utils.raft_trainer": [[30, 1, 1, "", "DEFAULT_CALLBACKS"], [30, 1, 1, "id0", "DEFAULT_PROGRESS_CALLBACK"], [30, 1, 1, "", "IS_SAGEMAKER_MP_POST_1_10"], [30, 1, 1, "", "OPTIMIZER_NAME"], [30, 2, 1, "", "RaftTrainer"], [30, 1, 1, "", "SCALER_NAME"], [30, 1, 1, "", "SCHEDULER_NAME"], [30, 1, 1, "", "TRAINER_STATE_NAME"], [30, 1, 1, "", "TRAINING_ARGS_NAME"], [30, 1, 1, "", "_is_native_cpu_amp_available"], [30, 1, 1, "", "logger"], [30, 1, 1, "", "skip_first_batches"]], "lmflow.pipeline.utils.raft_trainer.RaftTrainer": [[30, 3, 1, "", "_add_sm_patterns_to_gitignore"], [30, 3, 1, "", "_gather_and_numpify"], [30, 3, 1, "", "_get_collator_with_removed_columns"], [30, 3, 1, "", "_get_eval_sampler"], [30, 3, 1, "", "_get_output_dir"], [30, 3, 1, "", "_get_train_sampler"], [30, 3, 1, "", "_hp_search_setup"], [30, 3, 1, "", "_inner_training_loop"], [30, 3, 1, "", "_issue_warnings_after_load"], [30, 3, 1, "", "_load_best_model"], [30, 3, 1, "", "_load_from_checkpoint"], [30, 3, 1, "", "_load_optimizer_and_scheduler"], [30, 3, 1, "", "_load_rng_state"], [30, 3, 1, "", "_maybe_log_save_evaluate"], [30, 3, 1, "", "_move_model_to_device"], [30, 3, 1, "", "_nested_gather"], [30, 3, 1, "", "_one_train"], [30, 3, 1, "", "_pad_across_processes"], [30, 3, 1, "", "_prepare_input"], [30, 3, 1, "", "_prepare_inputs"], [30, 3, 1, "", "_push_from_checkpoint"], [30, 3, 1, "", "_remove_unused_columns"], [30, 3, 1, "", "_report_to_hp_search"], [30, 3, 1, "", "_rotate_checkpoints"], [30, 3, 1, "", "_save"], [30, 3, 1, "", "_save_checkpoint"], [30, 3, 1, "", "_save_tpu"], [30, 3, 1, "", "_set_signature_columns_if_needed"], [30, 3, 1, "", "_sorted_checkpoints"], [30, 3, 1, "", "_tune_save_checkpoint"], [30, 3, 1, "", "_wrap_model"], [30, 3, 1, "", "add_callback"], [30, 3, 1, "", "autocast_smart_context_manager"], [30, 3, 1, "", "call_model_init"], [30, 3, 1, "", "compute_loss"], [30, 3, 1, "", "compute_loss_context_manager"], [30, 3, 1, "", "create_model_card"], [30, 3, 1, "", "create_optimizer"], [30, 3, 1, "", "create_optimizer_and_scheduler"], [30, 3, 1, "", "create_scheduler"], [30, 3, 1, "", "evaluate"], [30, 3, 1, "", "evaluation_loop"], [30, 3, 1, "", "floating_point_ops"], [30, 3, 1, "", "get_eval_dataloader"], [30, 3, 1, "", "get_optimizer_cls_and_kwargs"], [30, 3, 1, "", "get_test_dataloader"], [30, 3, 1, "", "get_train_dataloader"], [30, 3, 1, "", "hyperparameter_search"], [30, 3, 1, "", "init_git_repo"], [30, 3, 1, "", "ipex_optimize_model"], [30, 3, 1, "", "is_local_process_zero"], [30, 3, 1, "", "is_world_process_zero"], [30, 3, 1, "", "log"], [30, 3, 1, "", "num_examples"], [30, 3, 1, "", "pop_callback"], [30, 3, 1, "", "predict"], [30, 3, 1, "", "prediction_loop"], [30, 3, 1, "", "prediction_step"], [30, 3, 1, "", "push_to_hub"], [30, 3, 1, "", "remove_callback"], [30, 3, 1, "", "save_model"], [30, 3, 1, "", "store_flos"], [30, 3, 1, "", "torch_jit_model_eval"], [30, 3, 1, "", "train"], [30, 3, 1, "", "training_step"]], "lmflow.utils": [[31, 0, 0, "-", "constants"], [32, 0, 0, "-", "data_utils"], [34, 0, 0, "-", "flash_attention"]], "lmflow.utils.constants": [[31, 1, 1, "", "DATASET_DESCRIPTION_MAP"], [31, 1, 1, "", "FLOAT_ONLY_DATASET_DESCRIPTION"], [31, 1, 1, "", "INSTANCE_FIELDS_MAP"], [31, 1, 1, "", "TEXT2TEXT_DATASET_DESCRIPTION"], [31, 1, 1, "", "TEXT2TEXT_DATASET_DETAILS"], [31, 1, 1, "", "TEXT2TEXT_DATASET_LONG_DESCRITION"], [31, 1, 1, "", "TEXT_ONLY_DATASET_DESCRIPTION"], [31, 1, 1, "", "TEXT_ONLY_DATASET_DETAILS"], [31, 1, 1, "", "TEXT_ONLY_DATASET_LONG_DESCRITION"]], "lmflow.utils.data_utils": [[32, 5, 1, "", "answer_extraction"], [32, 5, 1, "", "batchlize"], [32, 5, 1, "", "load_data"], [32, 5, 1, "", "set_random_seed"]], "lmflow.utils.flash_attention": [[33, 0, 0, "-", "gpt_neo_flash_attention"], [35, 0, 0, "-", "llama_flash_attention"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[33, 5, 1, "", "_attn"], [33, 5, 1, "", "forward"], [33, 5, 1, "", "replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention.llama_flash_attention": [[35, 5, 1, "", "_prepare_decoder_attention_mask"], [35, 5, 1, "", "forward"], [35, 5, 1, "", "replace_llama_attn_with_flash_attn"]], "lmflow.version": [[37, 1, 1, "", "__version__"]]}, "objtypes": {"0": "py:module", "1": "py:data", "2": "py:class", "3": "py:method", "4": "py:attribute", "5": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "data", "Python data"], "2": ["py", "class", "Python class"], "3": ["py", "method", "Python method"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "function", "Python function"]}, "titleterms": {"contributor": 0, "changelog": 1, "version": [1, 37], "0": 1, "1": [1, 44, 49], "mar": 1, "28": 1, "2023": 1, "about": 2, "lmflow": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 44, 50], "arg": [3, 5], "api": 4, "refer": 4, "modul": [5, 6, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 37], "content": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32, 33, 35, 37, 50], "class": [5, 6, 7, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30], "attribut": [5, 6, 13, 14, 20, 25, 28, 30], "dataset": [6, 7, 43, 44], "submodul": [7, 8, 15, 16, 26, 29, 34, 36], "packag": [7, 8], "subpackag": [8, 15, 26, 36], "model": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 39, 41, 49], "auto_model": 9, "base_model": 10, "decoder_model": 11, "encoder_decoder_model": 12, "hf_decoder_model": 13, "hf_encoder_decoder_model": 14, "interfac": [16, 17], "tunabl": 17, "regression_model": 18, "text_regression_model": 19, "pipelin": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "auto_pipelin": 20, "base_align": 21, "base_pipelin": 22, "base_tun": 23, "evalu": [24, 44, 46], "finetun": [25, 46, 47, 48, 49], "inferenc": 27, "function": [27, 32, 33, 35], "raft_align": 28, "util": [29, 30, 31, 32, 33, 34, 35, 36], "raft_train": 30, "constant": 31, "data_util": 32, "flash_attent": [33, 34, 35], "gpt_neo_flash_attent": 33, "llama_flash_attent": 35, "data": [38, 39, 46], "document": 39, "prepar": [39, 46], "tune": [39, 42, 50], "infer": [39, 40, 46], "fine": 42, "format": 43, "gener": 43, "support": [43, 50], "detail": 43, "textonli": 43, "text2text": 43, "benchmark": 44, "guid": 44, "nll": 44, "task": [44, 50], "set": 44, "setup": 44, "creat": 44, "your": 44, "file": 44, "registr": 44, "2": [44, 49], "lm": 44, "checkpoint": [45, 50], "llama": 45, "exampl": [46, 49], "reward": [48, 49], "rank": 48, "raft": 48, "introduct": [48, 49, 50], "algorithm": 48, "demo": 48, "custom": 48, "align": 48, "step": 49, "supervis": 49, "sft": 49, "featur": 50, "instruct": 50, "instal": 50, "citat": 50, "disclaim": 50, "indic": 50, "tabl": 50}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Contributors": [[0, "contributors"]], "Changelog": [[1, "changelog"]], "Version 0.0.1 (Mar 28, 2023)": [[1, "version-0-0-1-mar-28-2023"]], "About": [[2, "about"]], "lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "API Reference": [[4, "api-reference"]], "Module Contents": [[5, "module-contents"], [6, "module-contents"], [9, "module-contents"], [10, "module-contents"], [11, "module-contents"], [12, "module-contents"], [13, "module-contents"], [14, "module-contents"], [17, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [27, "module-contents"], [28, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [35, "module-contents"], [37, "module-contents"]], "Classes": [[5, "classes"], [6, "classes"], [7, "classes"], [9, "classes"], [10, "classes"], [11, "classes"], [12, "classes"], [13, "classes"], [14, "classes"], [17, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [27, "classes"], [28, "classes"], [30, "classes"]], "Attributes": [[5, "attributes"], [6, "attributes"], [13, "attributes"], [14, "attributes"], [20, "attributes"], [25, "attributes"], [28, "attributes"], [30, "attributes"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "Submodules": [[7, "submodules"], [8, "submodules"], [15, "submodules"], [16, "submodules"], [26, "submodules"], [29, "submodules"], [34, "submodules"], [36, "submodules"]], "Package Contents": [[7, "package-contents"], [8, "package-contents"]], "lmflow": [[8, "module-lmflow"]], "Subpackages": [[8, "subpackages"], [15, "subpackages"], [26, "subpackages"], [36, "subpackages"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "lmflow.pipeline.auto_pipeline": [[20, "module-lmflow.pipeline.auto_pipeline"]], "lmflow.pipeline.base_aligner": [[21, "module-lmflow.pipeline.base_aligner"]], "lmflow.pipeline.base_pipeline": [[22, "module-lmflow.pipeline.base_pipeline"]], "lmflow.pipeline.base_tuner": [[23, "module-lmflow.pipeline.base_tuner"]], "lmflow.pipeline.evaluator": [[24, "module-lmflow.pipeline.evaluator"]], "lmflow.pipeline.finetuner": [[25, "module-lmflow.pipeline.finetuner"]], "lmflow.pipeline": [[26, "module-lmflow.pipeline"]], "lmflow.pipeline.inferencer": [[27, "module-lmflow.pipeline.inferencer"]], "Functions": [[27, "functions"], [32, "functions"], [33, "functions"], [35, "functions"]], "lmflow.pipeline.raft_aligner": [[28, "module-lmflow.pipeline.raft_aligner"]], "lmflow.pipeline.utils": [[29, "module-lmflow.pipeline.utils"]], "lmflow.pipeline.utils.raft_trainer": [[30, "module-lmflow.pipeline.utils.raft_trainer"]], "lmflow.utils.constants": [[31, "module-lmflow.utils.constants"]], "lmflow.utils.data_utils": [[32, "module-lmflow.utils.data_utils"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[33, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "lmflow.utils.flash_attention": [[34, "module-lmflow.utils.flash_attention"]], "lmflow.utils.flash_attention.llama_flash_attention": [[35, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "lmflow.utils": [[36, "module-lmflow.utils"]], "lmflow.version": [[37, "module-lmflow.version"]], "Data": [[38, "data"]], "Documentation": [[39, "documentation"]], "Data and Model Preparation": [[39, "data-and-model-preparation"]], "Model Tuning": [[39, "model-tuning"]], "Model Inference": [[39, "model-inference"]], "Inference": [[40, "inference"], [46, "inference"]], "Model": [[41, "model"]], "Fine-tuning": [[42, "fine-tuning"]], "Dataset": [[43, "dataset"]], "Dataset Format in General": [[43, "dataset-format-in-general"]], "Supported Dataset and Detailed Formats": [[43, "supported-dataset-and-detailed-formats"]], "TextOnly": [[43, "textonly"]], "Text2Text": [[43, "text2text"]], "LMFlow Benchmark Guide": [[44, "lmflow-benchmark-guide"]], "1. NLL Task Setting": [[44, "nll-task-setting"]], "Setup": [[44, "setup"]], "Create Your Task Dataset File": [[44, "create-your-task-dataset-file"]], "Task Registration": [[44, "task-registration"]], "2. LM-Evaluation Task Setting": [[44, "lm-evaluation-task-setting"]], "Checkpoints": [[45, "checkpoints"], [50, "checkpoints"]], "LLaMA Checkpoint": [[45, "llama-checkpoint"]], "Examples": [[46, "examples"], [49, "examples"]], "Data preparation": [[46, "data-preparation"]], "Finetuning": [[46, "finetuning"]], "Evaluation": [[46, "evaluation"]], "Finetune": [[47, "finetune"]], "Reward rAnked FineTuning (RAFT)": [[48, "reward-ranked-finetuning-raft"]], "Introduction": [[48, "introduction"], [49, "introduction"], [50, "introduction"]], "Algorithm": [[48, "algorithm"]], "Demo": [[48, "demo"]], "Customized Alignments": [[48, "customized-alignments"]], "Reward Modeling": [[49, "reward-modeling"]], "Step 1 Supervised Finetuning (SFT)": [[49, "step-1-supervised-finetuning-sft"]], "Step 2 Reward Modeling": [[49, "step-2-reward-modeling"]], "LMFlow": [[50, "lmflow"]], "Features": [[50, "features"]], "Task Tuning": [[50, "task-tuning"]], "Instruction Tuning": [[50, "instruction-tuning"]], "Installation": [[50, "installation"]], "Content": [[50, "content"]], "Citation": [[50, "citation"]], "Disclaimer": [[50, "disclaimer"]], "Support": [[50, "support"]], "Indices and tables": [[50, "indices-and-tables"]]}, "indexentries": {"lmflow.args": [[3, "module-lmflow.args"], [5, "module-lmflow.args"]], "module": [[3, "module-lmflow.args"], [5, "module-lmflow.args"], [6, "module-lmflow.datasets.dataset"], [7, "module-lmflow.datasets"], [8, "module-lmflow"], [9, "module-lmflow.models.auto_model"], [10, "module-lmflow.models.base_model"], [11, "module-lmflow.models.decoder_model"], [12, "module-lmflow.models.encoder_decoder_model"], [13, "module-lmflow.models.hf_decoder_model"], [14, "module-lmflow.models.hf_encoder_decoder_model"], [15, "module-lmflow.models"], [16, "module-lmflow.models.interfaces"], [17, "module-lmflow.models.interfaces.tunable"], [18, "module-lmflow.models.regression_model"], [19, "module-lmflow.models.text_regression_model"], [20, "module-lmflow.pipeline.auto_pipeline"], [21, "module-lmflow.pipeline.base_aligner"], [22, "module-lmflow.pipeline.base_pipeline"], [23, "module-lmflow.pipeline.base_tuner"], [24, "module-lmflow.pipeline.evaluator"], [25, "module-lmflow.pipeline.finetuner"], [26, "module-lmflow.pipeline"], [27, "module-lmflow.pipeline.inferencer"], [28, "module-lmflow.pipeline.raft_aligner"], [29, "module-lmflow.pipeline.utils"], [30, "module-lmflow.pipeline.utils.raft_trainer"], [31, "module-lmflow.utils.constants"], [32, "module-lmflow.utils.data_utils"], [33, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"], [34, "module-lmflow.utils.flash_attention"], [35, "module-lmflow.utils.flash_attention.llama_flash_attention"], [36, "module-lmflow.utils"], [37, "module-lmflow.version"]], "autoarguments (class in lmflow.args)": [[5, "lmflow.args.AutoArguments"]], "benchmarkingarguments (class in lmflow.args)": [[5, "lmflow.args.BenchmarkingArguments"]], "datasetarguments (class in lmflow.args)": [[5, "lmflow.args.DatasetArguments"]], "evaluatorarguments (class in lmflow.args)": [[5, "lmflow.args.EvaluatorArguments"]], "finetunerarguments (class in lmflow.args)": [[5, "lmflow.args.FinetunerArguments"]], "inferencerarguments (class in lmflow.args)": [[5, "lmflow.args.InferencerArguments"]], "model_config_classes (in module lmflow.args)": [[5, "lmflow.args.MODEL_CONFIG_CLASSES"]], "model_types (in module lmflow.args)": [[5, "lmflow.args.MODEL_TYPES"]], "modelarguments (class in lmflow.args)": [[5, "lmflow.args.ModelArguments"]], "pipeline_argument_mapping (in module lmflow.args)": [[5, "lmflow.args.PIPELINE_ARGUMENT_MAPPING"]], "raftalignerarguments (class in lmflow.args)": [[5, "lmflow.args.RaftAlignerArguments"]], "__post_init__() (lmflow.args.datasetarguments method)": [[5, "lmflow.args.DatasetArguments.__post_init__"]], "__post_init__() (lmflow.args.modelarguments method)": [[5, "lmflow.args.ModelArguments.__post_init__"]], "answer_type (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.answer_type"]], "arch_type (lmflow.args.modelarguments attribute)": [[5, "id0"], [5, "lmflow.args.ModelArguments.arch_type"]], "block_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.block_size"]], "cache_dir (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.cache_dir"]], "config_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_name"]], "config_overrides (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.config_overrides"]], "customized_cache_dir (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.customized_cache_dir"]], "dataset_config_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_config_name"]], "dataset_name (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.dataset_name"]], "dataset_name (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_name"]], "dataset_path (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.dataset_path"]], "deepspeed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.deepspeed"]], "deepspeed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.deepspeed"]], "device (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.device"]], "disable_group_texts (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.disable_group_texts"]], "do_sample (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.do_sample"]], "eval_dataset_path (lmflow.args.finetunerarguments attribute)": [[5, "lmflow.args.FinetunerArguments.eval_dataset_path"]], "evaluate_block_size (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.evaluate_block_size"]], "get_pipeline_args_class() (lmflow.args.autoarguments method)": [[5, "lmflow.args.AutoArguments.get_pipeline_args_class"]], "group_texts_batch_size (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.group_texts_batch_size"]], "inference_batch_size_per_device (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.inference_batch_size_per_device"]], "inference_batch_size_per_device (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.inference_batch_size_per_device"]], "is_custom_dataset (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.is_custom_dataset"]], "keep_linebreaks (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.keep_linebreaks"]], "lm_evaluation_metric (lmflow.args.benchmarkingarguments attribute)": [[5, "lmflow.args.BenchmarkingArguments.lm_evaluation_metric"]], "local_rank (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.local_rank"]], "local_rank (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.local_rank"]], "lora_alpha (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_alpha"]], "lora_dropout (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_dropout"]], "lora_model_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_model_path"]], "lora_r (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_r"]], "lora_target_modules (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.lora_target_modules"]], "max_eval_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_eval_samples"]], "max_train_samples (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.max_train_samples"]], "metric (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.metric"]], "mixed_precision (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.mixed_precision"]], "mixed_precision (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.mixed_precision"]], "model_name_or_path (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_name_or_path"]], "model_revision (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_revision"]], "model_type (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.model_type"]], "num_raft_iteration (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.num_raft_iteration"]], "output_dir (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.output_dir"]], "output_max_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_max_length"]], "output_min_length (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_min_length"]], "output_reward_path (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.output_reward_path"]], "overwrite_cache (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.overwrite_cache"]], "preprocessing_num_workers (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.preprocessing_num_workers"]], "prompt_structure (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.prompt_structure"]], "raft_batch_size (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.raft_batch_size"]], "random_seed (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_seed"]], "random_seed (lmflow.args.inferencerarguments attribute)": [[5, "lmflow.args.InferencerArguments.random_seed"]], "random_shuffle (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.random_shuffle"]], "save_aggregated_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.save_aggregated_lora"]], "streaming (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.streaming"]], "test_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.test_file"]], "tokenizer_name (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.tokenizer_name"]], "top_reward_percentage (lmflow.args.raftalignerarguments attribute)": [[5, "lmflow.args.RaftAlignerArguments.top_reward_percentage"]], "torch_dtype (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.torch_dtype"]], "train_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.train_file"]], "use_accelerator_for_evaluator (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_accelerator_for_evaluator"]], "use_auth_token (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_auth_token"]], "use_fast_tokenizer (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_fast_tokenizer"]], "use_flash_attention (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_flash_attention"]], "use_lora (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_lora"]], "use_ram_optimized_load (lmflow.args.modelarguments attribute)": [[5, "lmflow.args.ModelArguments.use_ram_optimized_load"]], "use_wandb (lmflow.args.evaluatorarguments attribute)": [[5, "lmflow.args.EvaluatorArguments.use_wandb"]], "validation_file (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_file"]], "validation_split_percentage (lmflow.args.datasetarguments attribute)": [[5, "lmflow.args.DatasetArguments.validation_split_percentage"]], "dataset_types (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.DATASET_TYPES"]], "dataset (class in lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.Dataset"]], "key_instances (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_INSTANCES"]], "key_type (in module lmflow.datasets.dataset)": [[6, "lmflow.datasets.dataset.KEY_TYPE"]], "_check_data_format() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset.dataset class method)": [[6, "lmflow.datasets.dataset.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_data_args"]], "get_type() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.get_type"]], "lmflow.datasets.dataset": [[6, "module-lmflow.datasets.dataset"]], "map() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.map"]], "to_dict() (lmflow.datasets.dataset.dataset method)": [[6, "lmflow.datasets.dataset.Dataset.to_dict"]], "dataset (class in lmflow.datasets)": [[7, "lmflow.datasets.Dataset"]], "_check_data_format() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset._check_data_format"]], "create_from_dict() (lmflow.datasets.dataset class method)": [[7, "lmflow.datasets.Dataset.create_from_dict"]], "from_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.from_dict"]], "get_backend() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend"]], "get_backend_dataset() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_backend_dataset"]], "get_data_args() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_data_args"]], "get_type() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.get_type"]], "lmflow.datasets": [[7, "module-lmflow.datasets"]], "map() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.map"]], "to_dict() (lmflow.datasets.dataset method)": [[7, "lmflow.datasets.Dataset.to_dict"]], "__version__ (in module lmflow)": [[8, "lmflow.__version__"]], "internal_version (in module lmflow)": [[8, "lmflow.internal_version"]], "lmflow": [[8, "module-lmflow"]], "automodel (class in lmflow.models.auto_model)": [[9, "lmflow.models.auto_model.AutoModel"]], "get_model() (lmflow.models.auto_model.automodel class method)": [[9, "lmflow.models.auto_model.AutoModel.get_model"]], "lmflow.models.auto_model": [[9, "module-lmflow.models.auto_model"]], "basemodel (class in lmflow.models.base_model)": [[10, "lmflow.models.base_model.BaseModel"]], "lmflow.models.base_model": [[10, "module-lmflow.models.base_model"]], "decodermodel (class in lmflow.models.decoder_model)": [[11, "lmflow.models.decoder_model.DecoderModel"]], "lmflow.models.decoder_model": [[11, "module-lmflow.models.decoder_model"]], "encoderdecodermodel (class in lmflow.models.encoder_decoder_model)": [[12, "lmflow.models.encoder_decoder_model.EncoderDecoderModel"]], "lmflow.models.encoder_decoder_model": [[12, "module-lmflow.models.encoder_decoder_model"]], "hfdecodermodel (class in lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel"]], "models_support_flash_attention (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.MODELS_SUPPORT_FLASH_ATTENTION"]], "decode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.decode"]], "encode() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.inference"]], "lmflow.models.hf_decoder_model": [[13, "module-lmflow.models.hf_decoder_model"]], "logger (in module lmflow.models.hf_decoder_model)": [[13, "lmflow.models.hf_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.save"]], "tokenize() (lmflow.models.hf_decoder_model.hfdecodermodel method)": [[13, "lmflow.models.hf_decoder_model.HFDecoderModel.tokenize"]], "hfencoderdecodermodel (class in lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel"]], "decode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.decode"]], "encode() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.encode"]], "get_backend_model() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_backend_model"]], "get_max_length() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_max_length"]], "get_tokenizer() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.get_tokenizer"]], "inference() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.inference"]], "lmflow.models.hf_encoder_decoder_model": [[14, "module-lmflow.models.hf_encoder_decoder_model"]], "logger (in module lmflow.models.hf_encoder_decoder_model)": [[14, "lmflow.models.hf_encoder_decoder_model.logger"]], "merge_lora_weights() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.merge_lora_weights"]], "save() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.save"]], "tokenize() (lmflow.models.hf_encoder_decoder_model.hfencoderdecodermodel method)": [[14, "lmflow.models.hf_encoder_decoder_model.HFEncoderDecoderModel.tokenize"]], "lmflow.models": [[15, "module-lmflow.models"]], "lmflow.models.interfaces": [[16, "module-lmflow.models.interfaces"]], "tunable (class in lmflow.models.interfaces.tunable)": [[17, "lmflow.models.interfaces.tunable.Tunable"]], "lmflow.models.interfaces.tunable": [[17, "module-lmflow.models.interfaces.tunable"]], "regressionmodel (class in lmflow.models.regression_model)": [[18, "lmflow.models.regression_model.RegressionModel"]], "lmflow.models.regression_model": [[18, "module-lmflow.models.regression_model"]], "textregressionmodel (class in lmflow.models.text_regression_model)": [[19, "lmflow.models.text_regression_model.TextRegressionModel"]], "inference() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.inference"]], "lmflow.models.text_regression_model": [[19, "module-lmflow.models.text_regression_model"]], "register_inference_function() (lmflow.models.text_regression_model.textregressionmodel method)": [[19, "lmflow.models.text_regression_model.TextRegressionModel.register_inference_function"]], "autopipeline (class in lmflow.pipeline.auto_pipeline)": [[20, "lmflow.pipeline.auto_pipeline.AutoPipeline"]], "pipeline_mapping (in module lmflow.pipeline.auto_pipeline)": [[20, "lmflow.pipeline.auto_pipeline.PIPELINE_MAPPING"]], "get_pipeline() (lmflow.pipeline.auto_pipeline.autopipeline class method)": [[20, "lmflow.pipeline.auto_pipeline.AutoPipeline.get_pipeline"]], "lmflow.pipeline.auto_pipeline": [[20, "module-lmflow.pipeline.auto_pipeline"]], "basealigner (class in lmflow.pipeline.base_aligner)": [[21, "lmflow.pipeline.base_aligner.BaseAligner"]], "_check_if_alignable() (lmflow.pipeline.base_aligner.basealigner method)": [[21, "lmflow.pipeline.base_aligner.BaseAligner._check_if_alignable"]], "align() (lmflow.pipeline.base_aligner.basealigner method)": [[21, "lmflow.pipeline.base_aligner.BaseAligner.align"]], "lmflow.pipeline.base_aligner": [[21, "module-lmflow.pipeline.base_aligner"]], "basepipeline (class in lmflow.pipeline.base_pipeline)": [[22, "lmflow.pipeline.base_pipeline.BasePipeline"]], "lmflow.pipeline.base_pipeline": [[22, "module-lmflow.pipeline.base_pipeline"]], "basetuner (class in lmflow.pipeline.base_tuner)": [[23, "lmflow.pipeline.base_tuner.BaseTuner"]], "_check_if_tunable() (lmflow.pipeline.base_tuner.basetuner method)": [[23, "lmflow.pipeline.base_tuner.BaseTuner._check_if_tunable"]], "lmflow.pipeline.base_tuner": [[23, "module-lmflow.pipeline.base_tuner"]], "tune() (lmflow.pipeline.base_tuner.basetuner method)": [[23, "lmflow.pipeline.base_tuner.BaseTuner.tune"]], "evaluator (class in lmflow.pipeline.evaluator)": [[24, "lmflow.pipeline.evaluator.Evaluator"]], "_evaluate_acc_with_accelerator() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_accelerator"]], "_evaluate_acc_with_deepspeed() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_acc_with_deepspeed"]], "_evaluate_nll() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_nll"]], "_evaluate_ppl() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._evaluate_ppl"]], "_match() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator._match"]], "create_dataloader() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator.create_dataloader"]], "evaluate() (lmflow.pipeline.evaluator.evaluator method)": [[24, "lmflow.pipeline.evaluator.Evaluator.evaluate"]], "lmflow.pipeline.evaluator": [[24, "module-lmflow.pipeline.evaluator"]], "finetuner (class in lmflow.pipeline.finetuner)": [[25, "lmflow.pipeline.finetuner.Finetuner"]], "group_text() (lmflow.pipeline.finetuner.finetuner method)": [[25, "lmflow.pipeline.finetuner.Finetuner.group_text"]], "lmflow.pipeline.finetuner": [[25, "module-lmflow.pipeline.finetuner"]], "logger (in module lmflow.pipeline.finetuner)": [[25, "lmflow.pipeline.finetuner.logger"]], "tune() (lmflow.pipeline.finetuner.finetuner method)": [[25, "lmflow.pipeline.finetuner.Finetuner.tune"]], "lmflow.pipeline": [[26, "module-lmflow.pipeline"]], "inferencer (class in lmflow.pipeline.inferencer)": [[27, "lmflow.pipeline.inferencer.Inferencer"]], "create_dataloader() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.create_dataloader"]], "inference() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.inference"]], "lmflow.pipeline.inferencer": [[27, "module-lmflow.pipeline.inferencer"]], "rstrip_partial_utf8() (in module lmflow.pipeline.inferencer)": [[27, "lmflow.pipeline.inferencer.rstrip_partial_utf8"]], "stream_inference() (lmflow.pipeline.inferencer.inferencer method)": [[27, "lmflow.pipeline.inferencer.Inferencer.stream_inference"]], "raftaligner (class in lmflow.pipeline.raft_aligner)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner"]], "_get_batch_dataset_top() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._get_batch_dataset_top"]], "_initialize_trainer() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._initialize_trainer"]], "_load_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._load_dataset"]], "_load_input_dataset() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner._load_input_dataset"]], "align() (lmflow.pipeline.raft_aligner.raftaligner method)": [[28, "lmflow.pipeline.raft_aligner.RaftAligner.align"]], "lmflow.pipeline.raft_aligner": [[28, "module-lmflow.pipeline.raft_aligner"]], "logger (in module lmflow.pipeline.raft_aligner)": [[28, "lmflow.pipeline.raft_aligner.logger"]], "lmflow.pipeline.utils": [[29, "module-lmflow.pipeline.utils"]], "default_callbacks (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.DEFAULT_CALLBACKS"]], "default_progress_callback (in module lmflow.pipeline.utils.raft_trainer)": [[30, "id0"], [30, "lmflow.pipeline.utils.raft_trainer.DEFAULT_PROGRESS_CALLBACK"]], "is_sagemaker_mp_post_1_10 (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.IS_SAGEMAKER_MP_POST_1_10"]], "optimizer_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.OPTIMIZER_NAME"]], "rafttrainer (class in lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer"]], "scaler_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.SCALER_NAME"]], "scheduler_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.SCHEDULER_NAME"]], "trainer_state_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.TRAINER_STATE_NAME"]], "training_args_name (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.TRAINING_ARGS_NAME"]], "_add_sm_patterns_to_gitignore() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._add_sm_patterns_to_gitignore"]], "_gather_and_numpify() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._gather_and_numpify"]], "_get_collator_with_removed_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_collator_with_removed_columns"]], "_get_eval_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_eval_sampler"]], "_get_output_dir() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_output_dir"]], "_get_train_sampler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._get_train_sampler"]], "_hp_search_setup() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._hp_search_setup"]], "_inner_training_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._inner_training_loop"]], "_is_native_cpu_amp_available (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer._is_native_cpu_amp_available"]], "_issue_warnings_after_load() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._issue_warnings_after_load"]], "_load_best_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_best_model"]], "_load_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_from_checkpoint"]], "_load_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_optimizer_and_scheduler"]], "_load_rng_state() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._load_rng_state"]], "_maybe_log_save_evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._maybe_log_save_evaluate"]], "_move_model_to_device() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._move_model_to_device"]], "_nested_gather() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._nested_gather"]], "_one_train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._one_train"]], "_pad_across_processes() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._pad_across_processes"]], "_prepare_input() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_input"]], "_prepare_inputs() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._prepare_inputs"]], "_push_from_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._push_from_checkpoint"]], "_remove_unused_columns() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._remove_unused_columns"]], "_report_to_hp_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._report_to_hp_search"]], "_rotate_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._rotate_checkpoints"]], "_save() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save"]], "_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_checkpoint"]], "_save_tpu() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._save_tpu"]], "_set_signature_columns_if_needed() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._set_signature_columns_if_needed"]], "_sorted_checkpoints() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._sorted_checkpoints"]], "_tune_save_checkpoint() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._tune_save_checkpoint"]], "_wrap_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer._wrap_model"]], "add_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.add_callback"]], "autocast_smart_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.autocast_smart_context_manager"]], "call_model_init() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.call_model_init"]], "compute_loss() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss"]], "compute_loss_context_manager() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.compute_loss_context_manager"]], "create_model_card() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_model_card"]], "create_optimizer() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer"]], "create_optimizer_and_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_optimizer_and_scheduler"]], "create_scheduler() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.create_scheduler"]], "evaluate() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluate"]], "evaluation_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.evaluation_loop"]], "floating_point_ops() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.floating_point_ops"]], "get_eval_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_eval_dataloader"]], "get_optimizer_cls_and_kwargs() (lmflow.pipeline.utils.raft_trainer.rafttrainer static method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_optimizer_cls_and_kwargs"]], "get_test_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_test_dataloader"]], "get_train_dataloader() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.get_train_dataloader"]], "hyperparameter_search() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.hyperparameter_search"]], "init_git_repo() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.init_git_repo"]], "ipex_optimize_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.ipex_optimize_model"]], "is_local_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_local_process_zero"]], "is_world_process_zero() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.is_world_process_zero"]], "lmflow.pipeline.utils.raft_trainer": [[30, "module-lmflow.pipeline.utils.raft_trainer"]], "log() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.log"]], "logger (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.logger"]], "num_examples() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.num_examples"]], "pop_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.pop_callback"]], "predict() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.predict"]], "prediction_loop() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_loop"]], "prediction_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.prediction_step"]], "push_to_hub() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.push_to_hub"]], "remove_callback() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.remove_callback"]], "save_model() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.save_model"]], "skip_first_batches (in module lmflow.pipeline.utils.raft_trainer)": [[30, "lmflow.pipeline.utils.raft_trainer.skip_first_batches"]], "store_flos() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.store_flos"]], "torch_jit_model_eval() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.torch_jit_model_eval"]], "train() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.train"]], "training_step() (lmflow.pipeline.utils.raft_trainer.rafttrainer method)": [[30, "lmflow.pipeline.utils.raft_trainer.RaftTrainer.training_step"]], "dataset_description_map (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.DATASET_DESCRIPTION_MAP"]], "float_only_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.FLOAT_ONLY_DATASET_DESCRIPTION"]], "instance_fields_map (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.INSTANCE_FIELDS_MAP"]], "text2text_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_DESCRIPTION"]], "text2text_dataset_details (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_DETAILS"]], "text2text_dataset_long_descrition (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT2TEXT_DATASET_LONG_DESCRITION"]], "text_only_dataset_description (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_DESCRIPTION"]], "text_only_dataset_details (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_DETAILS"]], "text_only_dataset_long_descrition (in module lmflow.utils.constants)": [[31, "lmflow.utils.constants.TEXT_ONLY_DATASET_LONG_DESCRITION"]], "lmflow.utils.constants": [[31, "module-lmflow.utils.constants"]], "answer_extraction() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.answer_extraction"]], "batchlize() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.batchlize"]], "lmflow.utils.data_utils": [[32, "module-lmflow.utils.data_utils"]], "load_data() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.load_data"]], "set_random_seed() (in module lmflow.utils.data_utils)": [[32, "lmflow.utils.data_utils.set_random_seed"]], "_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[33, "lmflow.utils.flash_attention.gpt_neo_flash_attention._attn"]], "forward() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[33, "lmflow.utils.flash_attention.gpt_neo_flash_attention.forward"]], "lmflow.utils.flash_attention.gpt_neo_flash_attention": [[33, "module-lmflow.utils.flash_attention.gpt_neo_flash_attention"]], "replace_gpt_neo_attn_with_flash_attn() (in module lmflow.utils.flash_attention.gpt_neo_flash_attention)": [[33, "lmflow.utils.flash_attention.gpt_neo_flash_attention.replace_gpt_neo_attn_with_flash_attn"]], "lmflow.utils.flash_attention": [[34, "module-lmflow.utils.flash_attention"]], "_prepare_decoder_attention_mask() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[35, "lmflow.utils.flash_attention.llama_flash_attention._prepare_decoder_attention_mask"]], "forward() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[35, "lmflow.utils.flash_attention.llama_flash_attention.forward"]], "lmflow.utils.flash_attention.llama_flash_attention": [[35, "module-lmflow.utils.flash_attention.llama_flash_attention"]], "replace_llama_attn_with_flash_attn() (in module lmflow.utils.flash_attention.llama_flash_attention)": [[35, "lmflow.utils.flash_attention.llama_flash_attention.replace_llama_attn_with_flash_attn"]], "lmflow.utils": [[36, "module-lmflow.utils"]], "__version__ (in module lmflow.version)": [[37, "lmflow.version.__version__"]], "lmflow.version": [[37, "module-lmflow.version"]]}})